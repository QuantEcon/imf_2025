{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7abe680-11c7-4359-a80f-c871950e14e8",
   "metadata": {},
   "source": [
    "# Day 2: Data tools (Part 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150308ae-ba03-416e-a619-286bd6088317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468e135-4ab3-4f61-9f93-1265f27f2d4b",
   "metadata": {},
   "source": [
    "## `pandas`\n",
    "\n",
    "pandas is the primary tool for working with tabular data in Python.\n",
    "\n",
    "It provides two main data structures: **Series** (1-dimensional) and **DataFrame** (2-dimensional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db6bc1-f4fb-4978-adaa-e1258ae6dae1",
   "metadata": {},
   "source": [
    "### DataFrame basics\n",
    "\n",
    "You can think of a DataFrame as a \"super-powered\" spreadsheet - It has a notion of labeled rows and columns with values in each slot.\n",
    "\n",
    "Let's start by putting some US unemployment data by region into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db6bc1-f4fb-4978-adaa-e1258ae6dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "years = list(range(1995, 2017, 2))\n",
    "data = {\n",
    "    \"NorthEast\": [5.9, 5.6, 4.4, 3.8, 5.8, 4.9, 4.3, 7.1, 8.3, 7.9, 5.7],\n",
    "    \"MidWest\": [4.5, 4.3, 3.6, 4.0, 5.7, 5.7, 4.9, 8.1, 8.7, 7.4, 5.1],\n",
    "    \"South\": [5.3, 5.2, 4.2, 4.0, 5.7, 5.2, 4.3, 7.6, 9.1, 7.4, 5.5],\n",
    "    \"West\": [6.6, 6.0, 5.2, 4.6, 6.5, 5.5, 4.5, 8.6, 10.7, 8.5, 6.1],\n",
    "    \"National\": [5.6, 5.3, 4.3, 4.2, 5.8, 5.3, 4.6, 7.8, 9.1, 8., 5.7]\n",
    "}\n",
    "\n",
    "unemp = pd.DataFrame(data, index=years)\n",
    "unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db6bc1-f4fb-4978-adaa-e1258ae6dae3",
   "metadata": {},
   "source": [
    "**Key visual operations:**\n",
    "\n",
    "- `.head()` and `.tail()`: View first/last rows\n",
    "- `.describe()`: Summary statistics\n",
    "- `.dtypes()`: Type information\n",
    "\n",
    "There are lots of other useful operations that you will discover on your own as you work on the practice problems. One of the easiest ways to do this will be by interfacing with your favorite LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ac24d-8e93-4ad9-8976-353d2fc893b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary statistics:\")\n",
    "print(unemp.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f96932-1879-411c-901c-1ccd8f99b6d1",
   "metadata": {},
   "source": [
    "**Selecting values from a DataFrame**\n",
    "\n",
    "Two main ways of selecting\n",
    "\n",
    "- `.loc[row, col]`: Select by label\n",
    "- `.iloc[row, col]`: Select by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abefc1-3887-436b-b4d6-0a393a52fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[2009, \"MidWest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db6bc1-f4fb-4978-adaa-e1258ae6dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[2009, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de177c44-a1fe-4276-ad23-f22df0beb306",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[1995, [\"NorthEast\", \"National\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0822a1-44ad-41fc-bc80-1acd0b9ec9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[:, [\"NorthEast\", \"National\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709518e-61b7-43c3-9504-bef31db80a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[[1995, 2005, 2015], [\"NorthEast\", \"National\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d1600-3ec0-42ca-8785-c8cbdb694623",
   "metadata": {},
   "source": [
    "**Computation on columns**\n",
    "\n",
    "You often want to operate on a certain columns of data at a time or combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc581a68-43ea-4169-85e0-c451b340b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"West\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87dfa5-4200-4c73-bb51-ca5e9fa53ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"West\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d624622-50ab-48a0-a732-34da84bf6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"West\"] - unemp[\"MidWest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9efd46-5c4d-417a-9fe4-366d77a0bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"West\"].corr(unemp[\"MidWest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668243fa-3589-4b61-8634-95619abb2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f4844-a431-4cb6-a285-90cddb4bfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `eval` is extra efficient because it doesn't create as many copies\n",
    "unemp.eval(\"West / 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95013f02-e12c-4b00-93d0-645a17e6c351",
   "metadata": {},
   "source": [
    "**Datatypes**\n",
    "\n",
    "A handful of different data types can be stored in a DataFrame\n",
    "\n",
    "- Booleans (`bool`)  \n",
    "- Floating point numbers (`float64`)  \n",
    "- Integers (`int64`)  \n",
    "- Dates (`datetime`) — we will learn this soon  \n",
    "- Categorical data (`categorical`)  \n",
    "- Everything else, including strings (`object`)\n",
    "\n",
    "We will typically refer to the type of data stored in a column as its `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687adc3-2c34-40d8-a875-456160a3c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_unemp = unemp.copy()\n",
    "str_unemp[\"South\"] = str_unemp[\"South\"].astype(str)\n",
    "str_unemp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0083c-365c-45e3-8b68-3ac5a9d60792",
   "metadata": {},
   "source": [
    "Everything looks okay if we examine `str_unemp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fcdce-0aa7-4ff6-8f02-cee657ae736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e0e37-f862-4918-8370-6eaefa4075ff",
   "metadata": {},
   "source": [
    "but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ce5d4-8b36-4eee-ad89-47ff1ec190f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_unemp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eecb5c-dc7a-4fd4-b6e5-c1379118a3f1",
   "metadata": {},
   "source": [
    "**Creating new columns**\n",
    "\n",
    "We can create new data by assigning values to a column similar to how we assign values to a variable.\n",
    "\n",
    "In pandas, we create a new column of a DataFrame by writing:\n",
    "\n",
    "```python\n",
    "df[\"New Column Name\"] = new_values\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede543c-c924-4a47-87af-64523ec588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"UnweightedMean\"] = (\n",
    "    unemp[\"NorthEast\"] +\n",
    "    unemp[\"MidWest\"] +\n",
    "    unemp[\"South\"] +\n",
    "    unemp[\"West\"]\n",
    ") / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da900a8a-cb64-48e3-9465-e3c3d5d4625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e8f6f-420b-4256-a07d-7a001ea1da99",
   "metadata": {},
   "source": [
    "You can also change a particular value (or set of values) and rename columns/indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29756a-bb5b-47c3-bcd8-f6185f784149",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[1995, \"NorthEast\"] = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20006fd-5c9f-4510-a154-807164c831af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unemp = unemp.rename(\n",
    "    columns={\n",
    "        \"NorthEast\": \"northeast\",\n",
    "        \"MidWest\": \"midwest\",\n",
    "        \"South\": \"south\",\n",
    "        \"West\": \"west\",\n",
    "        \"National\": \"national\",\n",
    "        \"UnweightedMean\": \"unweightedmean\"\n",
    "    }\n",
    ")\n",
    "\n",
    "new_unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cfd4f-46ea-4d39-937a-1ca0b97a7279",
   "metadata": {},
   "source": [
    "### Datetime objects\n",
    "\n",
    "As economists, we often care about working with date objects since we're interested in how things change over time.\n",
    "\n",
    "Luckily for us, they are first-class citizens in the `pandas` ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce59d9-cdbf-4c22-9dde-33235b004ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up slightly larger data\n",
    "url = \"https://datascience.quantecon.org/assets/data/state_unemployment.csv\"\n",
    "unemp_raw = pd.read_csv(url, parse_dates=[\"Date\"])\n",
    "\n",
    "# Don't worry about the details here quite yet\n",
    "unemp_all = (\n",
    "    unemp_raw\n",
    "    .reset_index()\n",
    "    .pivot_table(index=\"Date\", columns=\"state\", values=\"UnemploymentRate\")\n",
    ")\n",
    "\n",
    "states = [\n",
    "    \"Arizona\", \"California\", \"Florida\", \"Illinois\",\n",
    "    \"Michigan\", \"New York\", \"Texas\"\n",
    "]\n",
    "unemp = unemp_all[states]\n",
    "unemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df7446-8dd4-4db5-a0db-368eedbc2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987718fb-3bf5-4a1e-9c11-a8982b50f8cc",
   "metadata": {},
   "source": [
    "**Selecting subset of dates**\n",
    "\n",
    "There are \"special\" ways to do selection on dates - You can always use the standard library's `datetime` type as seen below, but you can also treat dates as strings and they will get automatically converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede88c07-6b4c-4efe-a4a2-8df5e8d5e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[dt.datetime(2000, 1, 1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c876544-4f49-4d59-b7a9-e750458add3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data corresponding to a single date\n",
    "unemp.loc[\"2000-01-01\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73aa7ea-874b-48fd-acb5-6156fbb4badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for all days between New Years Day and June first in the year 2000\n",
    "unemp.loc[\"01/01/2000\":\"06/01/2000\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5833ac-6e61-466b-afeb-894f72bfc6df",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Let’s talk about *aggregations*.\n",
    "\n",
    "Loosely speaking, an aggregation is an operation that combines multiple values into a single value.\n",
    "\n",
    "For example, computing the mean of three numbers (for example `[0, 1, 2]`) returns a single number (1).\n",
    "\n",
    "We will use aggregations extensively as we analyze and manipulate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a23f2-ade2-4dbd-93e6-f9e4b56d9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in aggregations\n",
    "unemp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5833ac-6e61-466b-afeb-894f72bfc6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5833ac-6e61-466b-afeb-894f72bfc6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom aggregation\n",
    "def high_or_low(s):\n",
    "    \"\"\"Classify unemployment as high (>6.5) or low\"\"\"\n",
    "    return \"High\" if s.mean() > 6.5 else \"Low\"\n",
    "\n",
    "unemp.agg(high_or_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524d3fb-7fd7-4ce7-ab85-26adc2b3186e",
   "metadata": {},
   "source": [
    "### Transforms\n",
    "\n",
    "Many analytical operations do not necessarily involve an aggregation.\n",
    "\n",
    "The output of a function applied to a Series might need to be a new\n",
    "Series.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "- Compute the percentage change in unemployment from month to month.  \n",
    "- Calculate the cumulative sum of elements in each column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5332245-71c9-4816-83cb-3cf32a7a1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built in transforms\n",
    "unemp.pct_change().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b1f76-c981-4fa3-92f0-a9ac4e3aae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.diff().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c85e4-5be7-4555-b835-113e05198710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transform\n",
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "std_unemp = unemp.apply(standardize)\n",
    "std_unemp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a07a02-933b-4974-97b2-c2489a993317",
   "metadata": {},
   "source": [
    "There is a \"special case\" of transform where what you're actually interested in doing is transforming each number independent of the other numbers -- Something like taking the absolute value takes multiple values into multiple values but doesn't have inter-data dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed505db-f889-4300-8422-a556bd6d75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in scalar transform\n",
    "unemp.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b55b4-5385-46b4-9ce8-b8ee8167be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scalar transform\n",
    "def unemployment_classifier(ur):\n",
    "    \"\"\"\n",
    "    Classifies the unemployment rate as high, medium, or low\n",
    "    based on the value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ur : scalar(float)\n",
    "        The unemployment rate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : str\n",
    "        The classification \"high\", \"medium\", or \"low\"\n",
    "    \"\"\"\n",
    "    if ur > 6.5:\n",
    "        return \"high\"\n",
    "    elif ur > 4.5:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "unemp_bins = unemp.map(unemployment_classifier)\n",
    "unemp_bins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed74ea-5395-4edb-872f-d524b76a4284",
   "metadata": {},
   "source": [
    "**Boolean selection + query**\n",
    "\n",
    "Above we saw how we can select specific rows/columns or select by certain dates, but we may also need to select data based on conditions met by the data itself.\n",
    "\n",
    "Some examples are:\n",
    "\n",
    "- Restrict analysis to all individuals older than 18.  \n",
    "- Look at data that corresponds to particular time periods.  \n",
    "- Analyze only data that corresponds to a recession.  \n",
    "- Obtain data for a specific product or customer ID.  \n",
    "\n",
    "We will be able to do this by using a Series or list of boolean values to index into a Series or DataFrame.\n",
    "\n",
    "Let’s look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414d26fc-37f9-4330-936f-228601deae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp[\"NorthEast\"] < 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91606875-040f-49c2-9c54-acc19def3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[unemp[\"NorthEast\"] < 4.5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3ad4b-cd6a-4167-8583-4bcc71648019",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.query(\"NorthEast < 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ab64b-38e7-435b-8764-8f2d5d326246",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[(unemp[\"NorthEast\"] > 6.5) | (unemp[\"West\"] > 6.5), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894241e-8480-48e9-9c01-6ab52c7687d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[(unemp[\"NorthEast\"] > 6.5) & (unemp[\"West\"] > 6.5), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cffd1-b2e8-44d7-b27d-c28be4bf2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.loc[(unemp < 6.5).all(axis=1), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb07090-850a-4885-bf41-21f687bdbd22",
   "metadata": {},
   "source": [
    "### The Index\n",
    "\n",
    "We told you that the index was the “row labels” for the data\n",
    "\n",
    "This is true, but an index in pandas does much more than label the rows\n",
    "\n",
    "The [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html) says\n",
    "\n",
    "> Data alignment is intrinsic. The link between labels and data will not be broken unless done so explicitly by you.\n",
    "\n",
    "\n",
    "In practice, the index and column names are used to make sure the data is properly aligned when operating on multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb0a82-8db5-4392-aadd-3d2e40645fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load WDI data\n",
    "url = \"https://datascience.quantecon.org/assets/data/wdi_data.csv\"\n",
    "wdi_raw = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569b3b9-ebde-4882-b335-957ebae34880",
   "metadata": {},
   "source": [
    "To motivate the index, let's grab a subset of this data and see what happens when we \"add\" some columns of two different DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370880f5-b539-4d5f-9cd6-6c6f02a28176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = wdi_raw.head(5)\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38894a-bafd-483e-9bbf-b95ab2a0a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = wdi_raw.iloc[[0, 3, 2, 4], :]\n",
    "df_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761f38d-0f07-4e36-8a92-d52c0607a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.loc[:, [\"Exports\", \"Imports\"]] + df_tiny.loc[:, [\"Exports\", \"Imports\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0839fc2-4cde-49ae-b388-57eb49f2152f",
   "metadata": {},
   "source": [
    "For all (row, column) combinations that appear in both DataFrames (e.g. rows `[1, 3]` and columns `[Imports, Exports]`), the value of `im_ex_tiny` is equal to `df_tiny.loc[row, col] + im_ex.loc[row, col]`\n",
    "\n",
    "This happened even though the rows and columns were not in the same order\n",
    "\n",
    "We refer to this as pandas *aligning* the data for us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e50687-9223-4ec8-9eeb-624662f120b8",
   "metadata": {},
   "source": [
    "To see how awesome this is, think about how to do something similar in\n",
    "Excel:\n",
    "\n",
    "- `df_tiny` and `im_ex` would be in different sheets\n",
    "- The index and column names would be the first column and row in each sheet\n",
    "- We would have a third sheet to hold the sum\n",
    "- For each label in the first row and column of *either* the `df_tiny` sheet or the `im_ex` sheet we would have to do a `IFELSE` to check if the label exists in the other sheet and then a `VLOOKUP` to extract the value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33d817-ece5-4490-ad86-13852eb0c7e8",
   "metadata": {},
   "source": [
    "**Setting and resetting an index**\n",
    "\n",
    "You can choose which index to use -- The choice of index depends on the question at hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d8d70-b769-4df9-9c7a-094555a6b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_country = wdi_raw.set_index(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21b995-cc71-4990-a2a7-c3dfbca812c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_country.loc[\"Canada\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0fa3a-1504-4061-9c54-9759c1181108",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_year = wdi_raw.set_index(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768f844-d014-430f-b955-421243afd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_year.loc[2015, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a26b9-56e2-464e-8b0c-cf4f435d5575",
   "metadata": {},
   "source": [
    "You can also choose multiple columns to be your index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46835c3b-d4b6-41eb-b6ac-bd120ce90e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi = wdi_raw.set_index([\"country\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a835f754-c05e-4f5d-888e-dcdfb047e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a05e6e-60ed-4190-9720-3e5965cbfa0e",
   "metadata": {},
   "source": [
    "A few more rules for how indexing into a hierarchical index works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799cffb-4e8b-477d-b538-d4bfeb8df47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[(\"Canada\", 2015), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90826a9-92fc-4206-aaf0-e48bc7516217",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[([\"Canada\", \"United States\"], [2015, 2017]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89f876-f276-4b27-93f7-0ee34bbc9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi.loc[pd.IndexSlice[:, [2005, 2007, 2009]], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816a345-184e-433e-9e10-538df863a0eb",
   "metadata": {},
   "source": [
    "### Split-Apply-Combine (groupby)\n",
    "\n",
    "One powerful paradigm for analyzing data is the “Split-Apply-Combine” strategy\n",
    "\n",
    "This strategy has three steps:\n",
    "\n",
    "1. `Split`: split the data into groups based on values in one or more columns.  \n",
    "2. `Apply`: apply a function or routine to each group separately.  \n",
    "3. `Combine`: combine the output of the apply step into a DataFrame, using the group identifiers as the index\n",
    "\n",
    "We will cover the core concepts here\n",
    "\n",
    "We **strongly** encourage you to also study the [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dddd7b-a9da-4d5f-a12b-167e2d6b64c1",
   "metadata": {},
   "source": [
    "We are going to start with a \"toy dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255839a-b300-49d3-9d53-819d80c42746",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.arange(1, 7, dtype=float)\n",
    "C[[3, 5]] = np.nan\n",
    "df = pd.DataFrame({\n",
    "    \"A\" : [1, 1, 1, 2, 2, 2],\n",
    "    \"B\" : [1, 1, 2, 2, 1, 1],\n",
    "    \"C\": C,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64169fa-7ded-4153-81f1-aaa48ef66789",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbA = df.groupby(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88bc3e-df9e-407d-8d64-f2c1d5340c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gbA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e4661-b58c-48f1-b5cf-e3a96678814e",
   "metadata": {},
   "source": [
    "We can extract groups from the GroupBy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cc279-fca0-4baa-b192-e11ff98b658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbA.get_group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83668c82-fea1-4ead-8aa5-12ddfe84e0e8",
   "metadata": {},
   "source": [
    "We can also apply aggregations to the GroupBy object which will apply the aggregation to each possible group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259debb9-2e54-45bd-9a53-1cb4dbb51b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbA.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67aa509-0e20-47b4-9331-546068134695",
   "metadata": {},
   "source": [
    "Just like we could with the standard DataFrame object, we can apply custom aggregations/transformations to each group through the GroupBy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce44f5c-cd5f-4c11-ba6c-80edb88136b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(df):\n",
    "    \"Return the number of missing items in each column of df\"\n",
    "    return df.isnull().sum()\n",
    "\n",
    "df.groupby(\"A\").agg(num_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14171ad-bad4-4c13-8355-faa806faab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_by_b(df):\n",
    "    return df.nsmallest(2, \"B\")\n",
    "\n",
    "df.groupby(\"A\").apply(smallest_by_b, include_groups=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f55d7f-e49a-4d1b-bc03-09e44889b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function here\n",
    "def deviation_from_mean(x):\n",
    "    \"\"\"\n",
    "    Compute the deviation of each value of x from its mean\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: pd.Series, pd.DataFrame\n",
    "        The Series or DataFrame for which to do the computation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_hat: type(x)\n",
    "        The transformed version of x\n",
    "    \"\"\"\n",
    "    return x - x.mean()\n",
    "    \n",
    "\n",
    "\n",
    "# apply function here\n",
    "deviations = df.groupby(\"A\").apply(deviation_from_mean, include_groups=False)\n",
    "deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05509f91-cff4-45da-a6f1-66a612436614",
   "metadata": {},
   "source": [
    "There is a special helper, similar to `pd.IndexSlice` that allows us to do \"special things\" to the groups. This is especially helpful for resampling dates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913cd89-2c8e-40e6-b4b0-96eb984fcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"Date\"] = pd.date_range(\n",
    "    start=dt.datetime.today().strftime(\"%m/%d/%Y\"),\n",
    "    freq=\"BQE\",\n",
    "    periods=df.shape[0]\n",
    ")\n",
    "df2 = df2.set_index(\"A\")\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8667401-b993-4a01-920c-f764b1aaaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby(pd.Grouper(key=\"Date\", freq=\"YE\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c921bc-381c-456d-be6a-17b06e053eff",
   "metadata": {},
   "source": [
    "### Reshaping data\n",
    "\n",
    "\n",
    "While pushed more generally in the `R` language, the concept of “[tidy data](https://en.wikipedia.org/wiki/Tidy_data)” is helpful in understanding the objectives for reshaping data, which in turn makes advanced features like GroupBy more seamless.\n",
    "\n",
    "Hadley Wickham gives a terminology slightly better-adapted for the experimental sciences, but nevertheless useful for the social sciences.\n",
    "\n",
    "> A dataset is a collection of values, usually either numbers (if\n",
    "quantitative) or strings (if qualitative). Values are organized in two\n",
    "ways. Every value belongs to a variable and an observation. A variable\n",
    "contains all values that measure the same underlying attribute (like\n",
    "height, temperature, duration) across units. An observation contains all\n",
    "values measured on the same unit (like a person, or a day, or a race)\n",
    "across attributes. – [Tidy Data (Journal of Statistical Software 2013)](https://www.jstatsoft.org/index.php/jss/article/view/v059i10/v59i10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ffb55-f74f-4568-9e80-55824ae501b1",
   "metadata": {},
   "source": [
    "With this framing,\n",
    "\n",
    "> A dataset is messy or tidy depending on how rows, columns and tables are matched with observations, variables, and types. In tidy data:\n",
    "\n",
    "1.  Each variable forms a column.\n",
    "2.  Each observation forms a row.\n",
    "3.  Each type of observational unit forms a table.\n",
    "\n",
    "The “column” and “row” terms map directly to pandas columns and rows, while the “table” maps to a pandas DataFrame.\n",
    "\n",
    "The question that should come to mind anytime you're introduced to a dataset is, \"What uniquely identifies an “observation” in your data?\"\n",
    "\n",
    "Is it a country? A year? A combination of country and year?\n",
    "\n",
    "These will become the indices of your DataFrame.\n",
    "\n",
    "The concept of an \"observation\" may  not be unique to a dataset. For example, consider a time-series of county level GDP data.\n",
    "\n",
    "* The most \"pure\" form of tidy data would probably classify the year/country as the identifier and have a single variable of GDP\n",
    "* You could also consider the year to be the unique identifier and have each country's GDP be the variable\n",
    "* Or, a variable might even be the GDP in a given year with the countries being the unique identifiers\n",
    "\n",
    "What you consider to be an observation will depend on the question you're asking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf44c2a-3d4f-4b9b-8654-eae544dacd25",
   "metadata": {},
   "source": [
    "**Tall vs Wide**\n",
    "\n",
    "Data can either be \"tall\" or \"wide\"\n",
    "\n",
    "If we take our WDI data from above, it was a relatively \"wide\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74bc06-413e-4344-85bd-ad1f0e6da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44172e5c-cfed-4c90-833b-d6ea78bdd6df",
   "metadata": {},
   "source": [
    "This is what a \"tall\" version of that dataset would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa81cc7-4b53-4d91-9d16-93c12ae3560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_raw.melt(id_vars=[\"country\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e5f73-22b7-47e6-9c5c-3155afeee5a5",
   "metadata": {},
   "source": [
    "**Reshaping operations**\n",
    "\n",
    "The core reshaping operations are:\n",
    "\n",
    "* `.set_index`\n",
    "* `.reset_index`\n",
    "* `.stack`\n",
    "* `.unstack`\n",
    "\n",
    "Additionally, these get combined into some convenience reshaping functions called\n",
    "\n",
    "* `melt`\n",
    "* `pivot`\n",
    "* `pivot_table`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd8a54-d76e-48d5-8315-2f0d54c809f8",
   "metadata": {},
   "source": [
    "**`stack` and `unstack`**\n",
    "\n",
    "`stack` brings a \"column index\" into the \"row index\" and `unstack` brings a \"row index\" into a column index.\n",
    "\n",
    "Let's see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6b2be-2ff2-4d8d-9417-4e33ee3d4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wdi_raw.set_index([\"country\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7cb08-9ace-47c5-ac56-f8800e399a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa61d7-63ec-41f1-9f7d-188960ed5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47079bd-1eab-416c-b358-12d9892e3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfba5f-fb0f-4872-baf3-caa7f2fcccc9",
   "metadata": {},
   "source": [
    "Why might we want to have our data be stacked or unstacked in a particular way? Because it might make it easier to answer certain questions. For example, imagine that we wanted the average of each variable for each country over our time-series, then we could do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685184b-ea0c-4046-bb7a-1fe1b78f3b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack(level=\"country\").mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47275e7d-cbb0-409f-a05e-62d1b21ec672",
   "metadata": {},
   "source": [
    "**`melt` and `pivot`**\n",
    "\n",
    "It turns out that `melt` and `pivot` could be created using just the operations that you've already been taught (a great way to prove to yourself that you understand these operations is to reconstruct them from scratch!), but they are common enough operations that the convenience is helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da020fa-3476-492c-999f-92fe6818ca37",
   "metadata": {},
   "source": [
    "We already saw that `melt` takes a wide DataFrame and turns it into a tall DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d9435-4138-4764-a7fb-7e839d0dab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_tall = wdi_raw.melt(\n",
    "    id_vars=[\"country\", \"year\"], value_vars=[\"GovExpend\", \"GDP\"], var_name=\"variable\", value_name=\"value\"\n",
    ")\n",
    "\n",
    "wdi_tall.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10d2a3-817d-4e50-a53a-b59ced9bcd18",
   "metadata": {},
   "source": [
    "`pivot`/`pivot_table` can be thought of as basically the reverse of `melt`. It takes a tall DataFrame and makes it wide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bbe1d-21b5-4f1b-9e9c-019483e0c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_tall.pivot(columns=\"variable\", index=[\"country\", \"year\"], values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a0612-f162-47b2-849d-223d323b1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_tall.pivot_table(columns=\"variable\", index=[\"country\", \"year\"], values=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06a143-fb3c-4308-9092-89433f925bb3",
   "metadata": {},
   "source": [
    "They appear to do the same thing and they mostly do. `pivot_table` method is actually a slight generalization of `pivot`.\n",
    "\n",
    "It overcomes one limitation of `pivot`: It allows you to deal with duplicate entries by having you choose how to combine them.\n",
    "\n",
    "* I use `pivot` when I don't want multiple values to be put into the same cell.\n",
    "* I use `pivot_table` when I expect multiple values to go into a cell and specify an aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa656f9-cdf7-4245-af10-f2476beb4dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_tall.pivot(index=\"country\", columns=\"variable\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967f865-a5c4-4218-8cb0-68731646094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_tall.pivot_table(index=\"country\", columns=\"variable\", values=\"value\", aggfunc=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e763f-ee94-4934-ab98-4b3f7aa500e1",
   "metadata": {},
   "source": [
    "Here are some gifs for each of the operations that might help deepen your understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895feb6-372c-4892-aa6e-075df787e293",
   "metadata": {},
   "source": [
    "**`stack`**\n",
    "\n",
    "<img src=\"https://datascience.quantecon.org/_images/stack.gif\" alt=\"stack.gif\" style=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61ef2e-f4a0-47af-8a8c-41fdedb26d2b",
   "metadata": {},
   "source": [
    "**`unstack`**\n",
    "\n",
    "<img src=\"https://datascience.quantecon.org/_images/unstack_level0.gif\" alt=\"unstack\\_level0.gif\" style=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54458371-2969-4ca2-ba6d-060336eaa178",
   "metadata": {},
   "source": [
    "**`melt`**\n",
    "\n",
    "<img src=\"https://datascience.quantecon.org/_images/melt.gif\" alt=\"melt.gif\" style=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f",
   "metadata": {},
   "source": [
    "### Merge datasets\n",
    "\n",
    "We often need to combine data from multiple sources. pandas provides three main tools:\n",
    "\n",
    "1. `pd.concat`: Stack DataFrames\n",
    "2. `pd.merge`: Combine by matching keys (like SQL joins)\n",
    "3. `df.join`: Convenient wrapper for merge\n",
    "\n",
    "Let's work with country-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample datasets\n",
    "sq_miles = pd.Series({\n",
    "    \"United States\": 3.8,\n",
    "    \"Canada\": 3.8,\n",
    "    \"Germany\": 0.137,\n",
    "    \"United Kingdom\": 0.0936,\n",
    "    \"Russia\": 6.6,\n",
    "}, name=\"sq_miles\").to_frame()\n",
    "sq_miles.index.name = \"country\"\n",
    "\n",
    "# Population data\n",
    "pop_url = \"https://datascience.quantecon.org/assets/data/wdi_population.csv\"\n",
    "pop = pd.read_csv(pop_url).set_index([\"country\", \"year\"])\n",
    "\n",
    "print(\"Square miles:\")\n",
    "display(sq_miles)\n",
    "print(\"\\nPopulation (first few):\")\n",
    "display(pop.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb28db-a200-4329-88e0-13c64a855741",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdi_2017 = wdi_raw.query(\"year == 2017\").set_index(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a96d81-b303-47a6-a283-3cbde52946ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e042db7-2d48-4906-989c-1a1fb809caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f2",
   "metadata": {},
   "source": [
    "**pd.concat - stacking DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack side by side (axis=1)\n",
    "pd.concat([wdi_2017, sq_miles], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f4",
   "metadata": {},
   "source": [
    "**pd.merge - combining with keys:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on country\n",
    "pd.merge(wdi_2017, sq_miles, on=\"country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f6",
   "metadata": {},
   "source": [
    "**Different join types:**\n",
    "\n",
    "- `how=\"left\"`: Keep all rows from left DataFrame (default)\n",
    "- `how=\"right\"`: Keep all rows from right DataFrame\n",
    "- `how=\"inner\"`: Keep only matching rows\n",
    "- `how=\"outer\"`: Keep all rows from both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join - keeps Russia even though not in wdi_2017\n",
    "pd.merge(wdi_2017, sq_miles, on=\"country\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f8",
   "metadata": {},
   "source": [
    "**Merging on multiple keys:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad1a9a-3c3c-4ae1-b90f-9861ec9a450f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2016-2017 data\n",
    "wdi_recent = wdi.loc[pd.IndexSlice[:, [2016, 2017]], :].reset_index()\n",
    "\n",
    "# Merge with population on both country and year\n",
    "wdi_with_pop = pd.merge(\n",
    "    wdi_recent,\n",
    "    pop.reset_index(),\n",
    "    on=[\"country\", \"year\"]\n",
    ")\n",
    "\n",
    "# Calculate GDP per capita\n",
    "wdi_with_pop[\"GDP_per_capita\"] = wdi_with_pop[\"GDP\"] / wdi_with_pop[\"Population\"]\n",
    "wdi_with_pop[[\"country\", \"year\", \"GDP\", \"Population\", \"GDP_per_capita\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10283b6e-2364-4605-a183-ef4cbbae69b6",
   "metadata": {},
   "source": [
    "## `matplotlib`\n",
    "\n",
    "matplotlib is Python's main plotting library. pandas integrates with it seamlessly.\n",
    "\n",
    "We introduce here briefly but John has largely convinced me that there's no reason for me to write plotting code in most cases anymore... Claude typically (1) has better design taste than me (2) when it doesn't, I can just tell it why the graph is ugly and it will fix it, and (3) it remembers more about `matplotlib` than I've ever known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11448f5-8fc5-4747-9379-29ee2a3ef8ca",
   "metadata": {},
   "source": [
    "### Basic plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11448f5-8fc5-4747-9379-29ee2a3ef8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple line plot\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, np.sin(x))\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('sin(x)')\n",
    "ax.set_title('Sine Wave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a638b7-a89d-4b1b-932e-5816f47fbf07",
   "metadata": {},
   "source": [
    "### Plotting with `pandas`\n",
    "\n",
    "pandas DataFrames have a `.plot()` method that creates matplotlib figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a638b7-a89d-4b1b-932e-5816f47fbf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot of unemployment\n",
    "unemp.plot(figsize=(10, 6), title=\"Unemployment by Region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a638b7-a89d-4b1b-932e-5816f47fbf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "unemp.loc[2009].plot(kind=\"bar\", title=\"2009 Unemployment by Region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee342cb9-ddf0-4821-8278-0be081ce4207",
   "metadata": {},
   "source": [
    "### Advanced(ish) plotting\n",
    "\n",
    "**Subplots** let you create multiple plots in one figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee342cb9-ddf0-4821-8278-0be081ce4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 subplots for each region\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "unemp[\"NorthEast\"].plot(ax=axes[0, 0], title=\"NorthEast\")\n",
    "unemp[\"MidWest\"].plot(ax=axes[0, 1], title=\"MidWest\")\n",
    "unemp[\"South\"].plot(ax=axes[1, 0], title=\"South\")\n",
    "unemp[\"West\"].plot(ax=axes[1, 1], title=\"West\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee342cb9-ddf0-4821-8278-0be081ce4202",
   "metadata": {},
   "source": [
    "**Scatter plots** for relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee342cb9-ddf0-4821-8278-0be081ce4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: Consumption vs GDP\n",
    "wdi_2017.plot.scatter(\n",
    "    x=\"GDP\",\n",
    "    y=\"Consumption\",\n",
    "    title=\"Consumption vs GDP (2017)\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
